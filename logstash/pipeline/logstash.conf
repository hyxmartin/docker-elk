input {
        s3 {
                id => "airflow_daily_s3_id"
                bucket => "s3-cdp-prod-airflow-dag"
                prefix => "edw_daily/logs/bimart_branch_api_extraction_hourly_v2/extract_file_eats_marketing_eo_click/"
                interval => 30
                region => "ap-northeast-2"
                type => "airflow_s3_log"
                watch_for_new_files => true
                codec => multiline { 
                        pattern => "^\[[0-9]{4}-[0-9]{2}-[0-9]{2}" 
                        negate => true 
                        what => previous 
                        max_lines => 5000
                } 
        }

        s3 {
                id => "edw_kerberos_emr_id"
                bucket => "s3-cdp-prod-syslog"
                prefix => "datainfra/on-demand-emr/edw_emr_hive/edw_kerberos_emr_20201222/j-10PUTXTIL7DWE/containers/application_1611726021562_3716426/"
                interval => 30
                region => "ap-northeast-2"
                type => "emr_application_s3_log"
                exclude_pattern => "(\/stderr.gz|\/stdout.gz|\/syslog.gz)"
                gzip_pattern => "\.gz(ip)?$"
                watch_for_new_files => true
                codec => multiline { 
                        pattern => "^[0-9]{4}-[0-9]{2}-[0-9]{2}" 
                        negate => true 
                        what => previous 
                        max_lines => 5000
                } 
        }

        beats {
                port => 5044
                type => "beats_log"
        }

        tcp {
                port => 5000
                codec => multiline {
                        pattern => "^\'[0-9]{4}-[0-9]{2}-[0-9]{2}"
                        negate => true
                        what => previous
                        max_lines => 5000
                }
                type => "tcp_log"
        }
}

## Add your filters / logstash plugins configuration here
filter {
        mutate { remove_field => [ "_index", "_score", "_type", "_id" ] }
        if [type] == "airflow_s3_log" {

                grok {
                        match => { "message" => "\[%{TIMESTAMP_ISO8601:occurred_at:date}\] \{%{DATA:class}\} %{LOGLEVEL:loglevel} " } 
                        add_field => [ "received_at", "%{@timestamp}" ]
                        add_field => [ "path", "%{[@metadata][s3][key]}" ]
                        ## match => { "path" => "%{WORD:folder}\/(?<dummy_0>[^/]*)\/(?<dag_id>[^/]*)\/(?<task_id>[^/]*)\/%{TIMESTAMP_ISO8601:execution_date:date}\/(?<retry>[^.log]*) " }
                }
                
                dissect { mapping => { "path" => "%{folder}/%{dummy_0}/%{dag_id}/%{task_id}/%{execution_date}/%{retry}.log" } }

        } else if [type] == "emr_application_s3_log" {
                grok {
                        match => { "message" => "%{TIMESTAMP_ISO8601:occurred_at:date} \[%{LOGLEVEL:loglevel}\] \[%{DATA:method}\] \|%{DATA:class}\|: " } 
                        add_field => [ "received_at", "%{@timestamp}" ] 
                        add_field => [ "path", "%{[@metadata][s3][key]}" ]
                }

                dissect { mapping => { "path" => "%{dummy_0}/%{dummy_1}/%{edw_type}/%{edw_folder}/%{cluster_id}/%{dummy_2}/%{applicaiton_id}/%{container_id}/%{file}" } }

        } else if [type] == "beats_log" {
                grok {
                        match => { "message" => "%{TIMESTAMP_ISO8601:occurred_at:date} %{LOGLEVEL:loglevel} %{JAVACLASS:class} \(%{DATA:method}\)\:" }
                        add_field => [ "received_at", "%{@timestamp}" ]
                }

        } else if [type] == "tcp_log" {
                grok {
                        match => { "message" => "%{TIMESTAMP_ISO8601:occurred_at:date} %{LOGLEVEL:loglevel} %{JAVACLASS:class} \(%{DATA:method}\)\:" }
                        add_field => [ "received_at", "%{@timestamp}" ]
                }

        }
        
        date {
                match => [ "occurred_at", "yyyy-MM-dd HH:mm:ss,SSS", "yyyy-MM-dd HH:mm:ss.SSS", "ISO8601"]
                target => "@timestamp"
        }
}

output {
        if [type] == "airflow_s3_log" {
                elasticsearch {
                        hosts => "elasticsearch:9200"
                        index => "airflow-%{+YYYY.MM.dd}"
                        user => "elastic"
                        password => "changeme"
                        ecs_compatibility => disabled
                } 
        } else if [type] == "emr_application_s3_log" {
                elasticsearch {
                        hosts => "elasticsearch:9200"
                        index => "emr-application-%{+YYYY.MM.dd}"
                        user => "elastic"
                        password => "changeme"
                        ecs_compatibility => disabled
                } 
        } else {
                elasticsearch {
                        hosts => "elasticsearch:9200"
                        index => "logstash-%{+YYYY.MM.dd}"
                        user => "elastic"
                        password => "changeme"
                        ecs_compatibility => disabled
                } 
        }
}
